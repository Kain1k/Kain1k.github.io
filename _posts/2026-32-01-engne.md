---
title: "An introduction to Browser Exploitation Part 2: JavaScript Engine Internal"
date: 2026-01-31 00:00:00 +0800
categories: [Browser Exploitation]
tags: [Introduction, Browser Exploitation]
---
## The Flow of JavaScript Engines
JavaScript engine are an integral part of executing JavaScript code on systems. Previously, they were simply interpreters, but today, modern JavaScript engine are complex programs encompassing numerous performance-enhancing components such as optimized compilers and Just-In-Time (JIT) compilation.

There’s actually a multitude of different JS engines in use today, such as:

 - V8 - used in Chrome.
 - SpiderMonkey - used in Firefox.
 - Charka - previously used in IE and Edge.
 - JavaScriptCore - use in Safari.

As we know, JavaScript is an object-oriented, interpreted, and lightweight programming language. In interpreted languages, code is executed line by line and the result is returned immediately, so we don't need to compile the code into another form before the browser runs it. This doesn't usually make those languages ​​better in terms of performance. In that case, this is where compilation processes like Just-In-Time (JIT) compilation come into play; where JavaScript code is parsed into bytecode (an abstract form of machine code) and then further optimized by the JIT to make the code much more efficient and, in a sense, "faster".

Now, while each of the above-mentioned JavaScript engines can have different compilers and optimizers, all of them are pretty much designed and implemented the same way based on the EcmaScript standard (also used interchangeably with JavaScript). The EcmaScript specification details how JavaScript should be implemented by the browser so that a JavaScript program will run exactly the same way in all browsers.
![](compiler-pipeline-1.png)
Let’s break down the “flow” step by step and explain what each of these components does.

1. Parser: Once we execute JavaScript code, the code is passed into the JavaScript engine and we enter our first step, and that’s parsing the code. The parser converts the code into the following:
    - Tokens: The code is first broken down into “tokens”, such as Identifier, Number, String, Operator, etc. This is known “Lexical Analysis” or “Tokenizing”.
        - Example: var num = 42 gets broken down to var,num,=,42 and each “token” or item is then tagged with its type, so in this case it would be Keyword,Identifier,Operator,Number.
    - Abstract Syntax Tree (AST): Once the code has been parsed into tokens, the parser will convert those tokens into an AST. This part is called “Syntax Analysis” and it does what it says, it checks to make sure there are no syntax errors in the code.
        - Example: Using the above code example, the AST for that will look like so:
        ```
        {
            "type": "VariableDeclaration",
            "start": 0,
            "end": 13,
            "declarations": [
        {
            "type": "VariableDeclarator",
            "start": 4,
            "end": 12,
            "id": {
            "type": "Identifier",
            "start": 4,
            "end": 7,
            "name": "num"
            },
            "init": {
            "type": "Literal",
            "start": 10,
            "end": 12,
            "value": 42,
            "raw": "42"
            }
        }
        ],
            "kind": "var"
        }
        ```
2. Interpreter: Once an AST has been generated, it’s then passed into the Interpreter which walks the AST and generates bytecode. Once the bytecode has been generated, it is executed and the AST is deleted.
    - A list of Bytecodes for V8 can be found here.
    - An example of the bytecode for var num = 42; is shown below:
    ```
    LdaConstant [0]
    Star1
    Mov <closure>, r2
    CallRuntime [DeclareGlobals], r1-r2
    LdaSmi [42]
    StaGlobal [1], [0]
    LdaUndefined
    Return
    Compiler: The com
    ```
3. Compiler: The compiler works ahead of time by using something called a “Profiler” which monitors and watches code that should be optimized. If there is something known as a “hot function” the compiler takes that function and generates optimized machine code to execute. Otherwise, if it sees that a “hot function” that was optimized is no longer used, it will “deoptimize” it back to bytecode.

## JavaScript Engine Internal Concepts
When we run JavaScript, the JavaScript engine is the browser component that handles executing it. Over the years, these engines have grown from simple interpreters to complex, full blown compilation pipelines that include multiple layers of optimizations.

Diving too deep into the specifics of one engine without having a general "lay of the land" can be both daunting and detrimental. In this module, we will aim to define the concepts that JavaScript engines must implement while highlighting 'problem points' that force engines to make unique design decisions.
### JS Values

An immediate & fundamental architectural issue pops up almost as soon as we begin trying to implement a JS engine. Namely, these engines are written in C++, a language with strong typing requirements, while JavaScript has very generic, dynamic, and weakly typed objects.

Clearly, there must be a way to describe these JS objects using C++. We could choose to store a `type` and `value` in a class to approximate this:
```js
class JSValue {
    uint64_t type;
    Value* value;
}

// Pointer to object somewhere
JSValue* obj;
```
JavaScript can freely change the `type`, C++ can just use the `value` in whatever way is contextually appropriate. Speaking very coarsely, this is the strategy used to represent JS types and objects in both engines.

Unfortunately, the naive approach can quickly become wasteful. For example, consider the memory footprint if we try to store a number:
```
sizeof(JSValue*) + sizeof(JSValue) + sizeof(Value) >= 32
```
However, we know that JavaScript integers are at most 32 bits. In effect, we end up "spending" 32 bytes of memory in C++ to represent a single 32-bit number:

- 8 byte (64-bit) `uint64_t`
- 8 byte (64-bit) `pointer (Value *)`
- 8 byte (64-bit minimum) `Value`
- 8 byte (64-bit) `pointer (JSValue * obj)`

Although trivial for many applications, in the context of modern web browsers, this can become a huge waste of both memory and performance.
### JS Numbers

Given the problem of space-efficiency mentioned above, let's explore ways of more efficiently representing our special 32-bit numbers.

As a first attempt, we can try to inline the `value`. We know that this will contain a number, so there's no need for the pointer dereference:

```cpp
class JSNumber {
    uint64_t type;
    uint64_t value;
}
JSNumber* obj;
```

This ends up costing us 24 bytes, because we save a pointer dereference. However, we can do even better than that. JavaScript integers are only 32 bits long, so why not use some of the extra space within a single integer field to store type information?

```cpp
class JSNumber {
    uint64_t type_and_value;
}
JSNumber* obj;
```

Now we're down to 16 bytes, and if we avoid using pointers, just 8. This leads to another problem, however. Consider the following code:

```cpp
class JSNumber {
    uint64_t type_and_value;
}
JSNumber obj;
JSObject* obj2;
```

The native representations of both `JSNumber` and `JSObject *` just look like 64-bit numbers. How do the engines tell the difference between these? If they ever get it wrong, it would lead to a type-confusion (i.e. treating a number as a pointer or vice versa) and would very likely be exploitable.
### JS Objects

We know that full-blown JavaScript Objects are essential for the vast majority of "interesting" code to function.

Unlike our primitive Value or Number types, JS Objects require a lot more book-keeping from our end:

- Object Type
- Arbitrary Sized Key-Value store (properties)
- Prototype
- Length (for Arrays)
- Pointer to memory buffer (TypedArrays)
- etc

The simplest way forward is to try to extend our JSValue class to incorporate all the features we need:

```cpp
class JSObject {
    uint64_t type;
    std::unordered_map<JSValue, JSValue> properties;
    JSValue prototype;
    ... // Objects can add more fields
}
```

As you may imagine, this class also has some "waste" problems just like our initial JSNumber:

- Hash Map is bad for caching + wasteful for small number of keys
- Prototype and property keys duplicated for same object types

Right off the bat, we can make some improvements:

- Store properties as an Array
- Share type information

```cpp
class Type {
    uint64_t type;
    JSValue prototype;
    Name* property_names; // Indexes into property_array
    // other shared metadata
}
class JSObject {
    Type* type_information;
    JSValue* property_array;
    ... // Objects can add more fields
}
```

In this way, every "kind" of object shares the same `Type` information, so we don't have to "carry around" copies of it with every JavaScript object.

Furthermore, since most objects have relatively few properties, we save both time and space by choosing to store properties as an Array.

### Property Array

As mentioned, we can store properties in an array to offset some of the issues with using a hashmap:

```cpp
class JSObject {
    Type* type_information;
    JSValue* property_array; 
    ... // Objects can add more fields
}
```

However, this begs the question of what happens when we have a JS Object that **does** need a large number of properties. The answer: simply switch to using a hashmap when it makes sense performance wise!

Since we have a special case for *some* properties and **many** properties, why not also have one for a few properties:

```cpp
class JSObject {
    Type* type_information;
    JSValue* property_array ;
    JSValue[] inline_properties;
    ... // Objects can add more fields
}
```

In this manner, code can add properties to the `inline_properties` array and save a pointer dereference. This is especially useful for scenarios where you have **a lot** of small objects.

### Elements

Elements are just properties indexed by numbers instead of by keys:

```jsx
let b = {};
b['a'] = 0x41424344; // This is a named property
b[0] = 0x41424344; // This is an element

let c = [1,2,3,4]; // Arrays store elements
```

The easiest way to implement this is to treat elements like properties. Of course, we run into the problem of slow access, as this will grow at O(n).

There is also the issue of "large gaps" between elements:

```jsx
let a = [];
a[0] = 1;
a[100000] = 2;
```

Actually allocating and taking up that much memory would be extremely wasteful. Instead, the engines dynamically choose whether or not to use a traditional array or a hashmap ("sparse" array) based on how the array is being used.
### Shared Object Type

As mentioned in the JS Object section, sharing type information across objects is another way of saving space and increasing performance.

This is done by creating a structure that is used specifically for describing objects' types. Then, we simply use a pointer to that structure whenever we have a JS Object with that type.
![](share.png)